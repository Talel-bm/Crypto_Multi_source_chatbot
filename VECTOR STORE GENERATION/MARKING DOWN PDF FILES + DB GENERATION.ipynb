{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Go8gKgWvadwx",
        "outputId": "56e3c12f-d3b6-4bec-8a13-529c04e8efe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting marker-pdf[full]\n",
            "  Downloading marker_pdf-1.6.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting Pillow<11.0.0,>=10.1.0 (from marker-pdf[full])\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting anthropic<0.47.0,>=0.46.0 (from marker-pdf[full])\n",
            "  Downloading anthropic-0.46.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (8.1.8)\n",
            "Collecting ebooklib<0.19,>=0.18 (from marker-pdf[full])\n",
            "  Downloading EbookLib-0.18.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from marker-pdf[full])\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting ftfy<7.0.0,>=6.1.1 (from marker-pdf[full])\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.10.0)\n",
            "Collecting mammoth<2.0.0,>=1.9.0 (from marker-pdf[full])\n",
            "  Downloading mammoth-1.9.0-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting markdown2<3.0.0,>=2.5.2 (from marker-pdf[full])\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting markdownify<0.14.0,>=0.13.1 (from marker-pdf[full])\n",
            "  Downloading markdownify-0.13.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.65.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.72.0)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (3.1.5)\n",
            "Collecting pdftext<0.7.0,>=0.6.2 (from marker-pdf[full])\n",
            "  Downloading pdftext-0.6.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pre-commit<5.0.0,>=4.2.0 (from marker-pdf[full])\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2.11.3)\n",
            "Collecting pydantic-settings<3.0.0,>=2.0.3 (from marker-pdf[full])\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.0 (from marker-pdf[full])\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from marker-pdf[full])\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.8.1 (from marker-pdf[full])\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: regex<2025.0.0,>=2024.4.28 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (1.6.1)\n",
            "Collecting surya-ocr<0.14.0,>=0.13.1 (from marker-pdf[full])\n",
            "  Downloading surya_ocr-0.13.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (4.67.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.45.2 in /usr/local/lib/python3.11/dist-packages (from marker-pdf[full]) (4.51.1)\n",
            "Collecting weasyprint<64.0,>=63.1 (from marker-pdf[full])\n",
            "  Downloading weasyprint-63.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (4.13.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from ebooklib<0.19,>=0.18->marker-pdf[full]) (5.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from ebooklib<0.19,>=0.18->marker-pdf[full]) (1.17.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0.0,>=6.1.1->marker-pdf[full]) (0.2.13)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (15.0.1)\n",
            "Collecting cobble<0.2,>=0.1.3 (from mammoth<2.0.0,>=1.9.0->marker-pdf[full])\n",
            "  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/lib/python3.11/dist-packages (from markdownify<0.14.0,>=0.13.1->marker-pdf[full]) (4.13.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->marker-pdf[full]) (2.0.0)\n",
            "Collecting pypdfium2==4.30.0 (from pdftext<0.7.0,>=0.6.2->marker-pdf[full])\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cfgv>=2.0.0 (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\n",
            "  Downloading identify-2.6.9-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full]) (6.0.2)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\n",
            "  Downloading virtualenv-20.30.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->marker-pdf[full]) (0.4.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->marker-pdf[full])\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.6.1->marker-pdf[full]) (3.6.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from surya-ocr<0.14.0,>=0.13.1->marker-pdf[full]) (4.11.0.86)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=4.3.6 in /usr/local/lib/python3.11/dist-packages (from surya-ocr<0.14.0,>=0.13.1->marker-pdf[full]) (4.3.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.5.1->marker-pdf[full])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.5.1->marker-pdf[full]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.5.1->marker-pdf[full]) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.2->marker-pdf[full]) (0.5.3)\n",
            "Collecting pydyf>=0.11.0 (from weasyprint<64.0,>=63.1->marker-pdf[full])\n",
            "  Downloading pydyf-0.11.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (1.17.1)\n",
            "Collecting tinyhtml5>=2.0.0b1 (from weasyprint<64.0,>=63.1->marker-pdf[full])\n",
            "  Downloading tinyhtml5-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint<64.0,>=63.1->marker-pdf[full]) (1.4.0)\n",
            "Collecting cssselect2>=0.1 (from weasyprint<64.0,>=63.1->marker-pdf[full])\n",
            "  Downloading cssselect2-0.8.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting Pyphen>=0.9.1 (from weasyprint<64.0,>=63.1->marker-pdf[full])\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full]) (4.57.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.9->markdownify<0.14.0,>=0.13.1->marker-pdf[full]) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint<64.0,>=63.1->marker-pdf[full]) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.1->weasyprint<64.0,>=63.1->marker-pdf[full]) (0.5.1)\n",
            "Collecting brotli>=1.0.1 (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full])\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting zopfli>=0.1.4 (from fonttools[woff]>=4.0.0->weasyprint<64.0,>=63.1->marker-pdf[full])\n",
            "  Downloading zopfli-0.2.3.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.47.0,>=0.46.0->marker-pdf[full]) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (2.3.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit<5.0.0,>=4.2.0->marker-pdf[full])\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.5.1->marker-pdf[full]) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.0.0->marker-pdf[full]) (0.6.1)\n",
            "Downloading anthropic-0.46.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.2/223.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mammoth-1.9.0-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-0.13.1-py3-none-any.whl (10 kB)\n",
            "Downloading pdftext-0.6.2-py3-none-any.whl (23 kB)\n",
            "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading surya_ocr-0.13.1-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading weasyprint-63.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marker_pdf-1.6.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.2/165.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\n",
            "Downloading cssselect2-0.8.0-py3-none-any.whl (15 kB)\n",
            "Downloading identify-2.6.9-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pydyf-0.11.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tinyhtml5-2.0.0-py3-none-any.whl (39 kB)\n",
            "Downloading virtualenv-20.30.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zopfli-0.2.3.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (850 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m850.6/850.6 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ebooklib\n",
            "  Building wheel for ebooklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ebooklib: filename=EbookLib-0.18-py3-none-any.whl size=38778 sha256=f9c542ceb335668dd1e39cb3d90d51e654b71af65edd02f74b1b5f77a304790f\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/2b/63/68307c736d5a2fafeebe9df3e5eccacfe892204ce1fd31a03c\n",
            "Successfully built ebooklib\n",
            "Installing collected packages: filetype, distlib, brotli, zopfli, XlsxWriter, virtualenv, tinyhtml5, rapidfuzz, python-dotenv, Pyphen, pypdfium2, pydyf, Pillow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nodeenv, markdown2, identify, ftfy, ebooklib, cobble, cfgv, python-pptx, pre-commit, nvidia-cusparse-cu12, nvidia-cudnn-cu12, markdownify, mammoth, cssselect2, weasyprint, pydantic-settings, nvidia-cusolver-cu12, anthropic, pdftext, surya-ocr, marker-pdf\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Pillow-10.4.0 Pyphen-0.17.2 XlsxWriter-3.2.2 anthropic-0.46.0 brotli-1.1.0 cfgv-3.4.0 cobble-0.1.4 cssselect2-0.8.0 distlib-0.3.9 ebooklib-0.18 filetype-1.2.0 ftfy-6.3.1 identify-2.6.9 mammoth-1.9.0 markdown2-2.5.3 markdownify-0.13.1 marker-pdf-1.6.2 nodeenv-1.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pdftext-0.6.2 pre-commit-4.2.0 pydantic-settings-2.8.1 pydyf-0.11.0 pypdfium2-4.30.0 python-dotenv-1.1.0 python-pptx-1.0.2 rapidfuzz-3.13.0 surya-ocr-0.13.1 tinyhtml5-2.0.0 virtualenv-20.30.0 weasyprint-63.1 zopfli-0.2.3.post1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "1cf5daea1cf74a02b7a26e476b544258",
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install marker-pdf[full]\n",
        "!pip install chonkie[all]\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "GEMINI_API_KEY = ''\n",
        "MODEL_ID =\"gemini-2.0-flash-001\"#\"gemini-2.5-pro-exp-03-25\"#\"gemini-2.0-flash-lite\"\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-N5XrnSpauIP"
      },
      "outputs": [],
      "source": [
        "from marker.converters.pdf import PdfConverter\n",
        "from marker.models import create_model_dict\n",
        "from marker.output import text_from_rendered\n",
        "from marker.config.parser import ConfigParser\n",
        "\n",
        "def markdown_doc(file_address,GEMINI_API_KEY):\n",
        "  config = {\n",
        "    \"output_format\": \"markdown\",\n",
        "    \"ADDITIONAL_KEY\": f\"--gemini_{GEMINI_API_KEY}\"\n",
        "  }\n",
        "  config_parser = ConfigParser(config)\n",
        "  converter = PdfConverter(\n",
        "    config=config_parser.generate_config_dict(),\n",
        "    artifact_dict=create_model_dict(),\n",
        "    processor_list=config_parser.get_processors(),\n",
        "    renderer=config_parser.get_renderer(),\n",
        "    llm_service=config_parser.get_llm_service()\n",
        "  )\n",
        "  rendered = converter(file_address)\n",
        "  text, _, images = text_from_rendered(rendered)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph4ywqoSf_vg",
        "outputId": "55285c28-bf8a-452d-cf32-fafcd6552224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 5/5 [00:03<00:00,  1.31it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 7/7 [00:00<00:00, 58.44it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Recognizing tables: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/Etherium whitepaper - 12-2-2025.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 4/4 [00:00<00:00, 71.73it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Recognizing tables: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/aave-v2-whitepaper.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 7/7 [00:08<00:00,  1.21s/it]\n",
            "Running OCR Error Detection: 100%|██████████| 11/11 [00:00<00:00, 58.63it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 40/40 [02:53<00:00,  4.35s/it]\n",
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
            "Recognizing Text: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
            "Recognizing tables: 100%|██████████| 4/4 [00:03<00:00,  1.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/Etherium yellow paper.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 84.72it/s]\n",
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
            "Recognizing Text: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
            "Texify inference: 100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/curvefi_whitepaper_stableswaps.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 23/23 [00:16<00:00,  1.40it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 34/34 [00:00<00:00, 54.00it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Recognizing tables: 100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/chainlink-whitepaper-v2.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 3/3 [00:00<00:00, 65.16it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 5/5 [00:17<00:00,  3.57s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/balancer white paper.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 6/6 [00:00<00:00, 61.58it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
            "Recognizing Text: 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]\n",
            "Recognizing tables: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/Liquity v2 - Whitepaper rev. 0.3 (November, 2024) (1).txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 63.10it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/curvefi_whitepaper_curve_stablecoin.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 2/2 [00:01<00:00,  1.57it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 3/3 [00:00<00:00, 84.00it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/bitcoin.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 2/2 [00:01<00:00,  1.19it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 3/3 [00:00<00:00, 78.32it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 3/3 [00:04<00:00,  1.48s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/uniswap v2 core.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 7/7 [00:00<00:00, 63.21it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/White Paper -The Maker Protocol_ MakerDAO’s Multi-Collateral Dai (MCD) System-FINAL- 021720.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n",
            "Running OCR Error Detection: 100%|██████████| 7/7 [00:00<00:00, 56.42it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Recognizing tables: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/compound - documentation.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 4/4 [00:00<00:00, 77.57it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Recognizing tables: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/eliptic curve cryptography.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 79.56it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/curvefi_whitepaper_curvedao.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 53.29it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/cosmos WHITEPAPER.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n",
            "Running OCR Error Detection: 100%|██████████| 3/3 [00:00<00:00, 83.57it/s]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Texify inference: 100%|██████████| 7/7 [00:11<00:00,  1.66s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]\n",
            "Recognizing tables: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/uniswap v3 core.txt'\n",
            "Loaded layout model s3://layout/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded texify model s3://texify/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded recognition model s3://text_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded table recognition model s3://table_recognition/2025_02_18 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://text_detection/2025_02_28 on device cuda with dtype torch.float16\n",
            "Loaded detection model s3://inline_math_detection/2025_02_24 on device cuda with dtype torch.float16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Recognizing layout: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 88.76it/s]\n",
            "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
            "Recognizing Text: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s]\n",
            "Texify inference: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n",
            "Detecting bboxes: 0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Markdown to '/content/CRYPTO PAPERS MARKDOWN/curve_fi_whitepaper_cryptoswap.txt'\n",
            "\n",
            "--- Processing Complete ---\n",
            "Successfully processed files: 17\n",
            "Files with errors: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "input_folder_address = '/content/CRYPTO PAPERS'\n",
        "output_folder_address = '/content/CRYPTO PAPERS MARKDOWN'\n",
        "\n",
        "os.makedirs(output_folder_address, exist_ok=True)\n",
        "\n",
        "processed_count = 0\n",
        "error_count = 0\n",
        "for filename in os.listdir(input_folder_address):\n",
        "    if not filename.endswith('.pdf'):\n",
        "        continue\n",
        "    input_pdf_path = os.path.join(input_folder_address, filename)\n",
        "    # Construct the output markdown file path\n",
        "    base_filename = os.path.splitext(filename)[0] # Get filename without extension\n",
        "    output_md_filename = base_filename + \".txt\"\n",
        "    output_md_path = os.path.join(output_folder_address, output_md_filename)\n",
        "\n",
        "    # Run the conversion function\n",
        "    markdown_content = markdown_doc(input_pdf_path, GEMINI_API_KEY)\n",
        "\n",
        "    # Save the result if conversion was successful\n",
        "    if markdown_content is not None:\n",
        "        try:\n",
        "            with open(output_md_path, 'w', encoding='utf-8') as f_out:\n",
        "                f_out.write(markdown_content)\n",
        "            print(f\"Saved Markdown to '{output_md_path}'\")\n",
        "            processed_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR saving file '{output_md_path}': {e}\")\n",
        "            error_count += 1\n",
        "    else:\n",
        "        # markdown_doc already printed an error\n",
        "        error_count += 1\n",
        "\n",
        "print(\"\\n--- Processing Complete ---\")\n",
        "print(f\"Successfully processed files: {processed_count}\")\n",
        "print(f\"Files with errors: {error_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "import chromadb\n",
        "import chromadb.utils.embedding_functions as embedding_functions\n",
        "from chonkie import RecursiveChunker\n",
        "# Initialize the chunker\n",
        "chunker = RecursiveChunker() #<- I used a fresh library called chonkie for chunking here\n",
        "\n",
        "def create_vector_database(\n",
        "    input_folder: str,\n",
        "    output_folder: str,\n",
        "    name: str,\n",
        "    YOUR_API_KEY:str,\n",
        "    batch_size: int = 100\n",
        ") -> chromadb.Collection:\n",
        "    # Validate inputs\n",
        "    if not os.path.exists(input_folder):\n",
        "        raise ValueError(f\"Input folder {input_folder} does not exist\")\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Initialize ChromaDB\n",
        "    client = chromadb.PersistentClient(path=output_folder)\n",
        "    google_ef = embedding_functions.GoogleGenerativeAiEmbeddingFunction(\n",
        "        api_key=YOUR_API_KEY,\n",
        "        task_type=\"RETRIEVAL_QUERY\"\n",
        "    )\n",
        "    \n",
        "    collection = client.get_or_create_collection(\n",
        "        name=name,\n",
        "        embedding_function=google_ef\n",
        "    )\n",
        "\n",
        "    # Get document paths with progress bar\n",
        "    files = [\n",
        "        os.path.join(input_folder, f)\n",
        "        for f in os.listdir(input_folder)\n",
        "        if os.path.isfile(os.path.join(input_folder, f))\n",
        "    ]\n",
        "\n",
        "    # Process files with error handling and progress tracking\n",
        "    for file_idx, file_address in enumerate(tqdm(files, desc=\"Processing files\")):\n",
        "        try:\n",
        "            with open(file_address, 'r', encoding='utf-8') as f:\n",
        "                full_text = f.read()\n",
        "            print(\"pour : \",file_address,\" we got\",full_text)\n",
        "            chunks_ = chunker(full_text)\n",
        "            chunks = [chunk.text for chunk in chunks_]\n",
        "            \n",
        "            # Generate unique IDs and metadata\n",
        "            ids = []\n",
        "            documents = []\n",
        "            metadatas = []\n",
        "\n",
        "            for chunk_idx, chunk in enumerate(chunks):\n",
        "                unique_id = f\"doc_{file_idx}_chunk_{chunk_idx}\"\n",
        "                ids.append(unique_id)\n",
        "                documents.append(chunk)\n",
        "                metadatas.append({\n",
        "                    \"source_file\": os.path.basename(file_address),\n",
        "                    \"chunk_index\": chunk_idx,\n",
        "                    \"file_index\": file_idx\n",
        "                })\n",
        "\n",
        "                # Batch processing for efficiency\n",
        "                if len(documents) >= batch_size:\n",
        "                    collection.add(\n",
        "                        ids=ids,\n",
        "                        documents=documents,\n",
        "                        metadatas=metadatas\n",
        "                    )\n",
        "                    ids, documents, metadatas = [], [], []\n",
        "\n",
        "            # Add remaining documents in partial batch\n",
        "            if documents:\n",
        "                collection.add(\n",
        "                    ids=ids,\n",
        "                    documents=documents,\n",
        "                    metadatas=metadatas\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to process {file_address}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    return collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "collection = create_vector_database(\n",
        "     input_folder = \"CRYPTO PAPERS + MARKDOWN\",\n",
        "     output_folder = \"Documents\\DOC DB\",\n",
        "     YOUR_API_KEY = GEMINI_API_KEY,\n",
        "     name =\"crypto_db\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
